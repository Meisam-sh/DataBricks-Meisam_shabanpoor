{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf3a378d-d4df-4a1e-a50e-77ca4a2a0eef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Access Azure dataset using Access Key\n",
    "- setbthe spark.config fs.azure.acount.key\n",
    "- list files from demo container\n",
    "- Read data from circuit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c0350f3-24de-4cc3-ae45-4cebe9d5bd00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"fs.azure.account.key\\formula.formula1dl.dfs.core.windows.net\",\n",
    "               \"4fsdnvl;akdfh34@$I&$jdhdlopdspfi*&^#BVJ()HBJHGF\")\n",
    "#first section of the code above is the prefix\\storageaccountname(here is formula1dl)\n",
    "# second section of the code above is the access key which copied from azure datalake /Storage account/Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52b657db-1b1d-4dea-b3cf-57497bde0cea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#with executing of this code lists the files of this data lake(on this example circuets.csv)\n",
    "display(dbutils.fs.ls(\"abfss://demo@formula1dl.dfs.core.windows.net\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93f80400-d8e7-4284-b084-e661af26407b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read data from csv file. Notice reading from csv by spark is a little different with reading by pandas\n",
    "# # in pandas we use read_csv but spark.read.csv is used based on spark library  \n",
    "spark.rea.csv(\"abfss://demo@fomula1dl.dfs.code.windows.net/circuets.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Access Azure dataset by access key",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
