{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf3a378d-d4df-4a1e-a50e-77ca4a2a0eef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Access Azure dataset using SAS Key\n",
    "- setbthe spark.config to SAS token\n",
    "- list files from demo container\n",
    "- Read data from circuit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c0350f3-24de-4cc3-ae45-4cebe9d5bd00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"fs.azure.account.auth.type.formula1dl.dfs.core.windows.net\",\"SAS\")\n",
    "spark.conf.set(\"fs.azure.sas.token.provider.type.formula1dl.dfs.core.windows.net\",\"org.apache.hadoop.fs.azure.sas.FixedSASTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.sas.fixed.token.formula1dl.dfs.core.windows.net\",\"sp=rl&st=24-10-23T13:46:32&spr=https&sv=2024-10-23d,smfdslkfwe39#@#Rdfsf!@$DFS=\")\n",
    "#These lines are embeded to config the SAS token which made in Azure on the containers/generate SAS . we do it and put the token code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52b657db-1b1d-4dea-b3cf-57497bde0cea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#with executing of this code lists the files of this data lake(on this example circuets.csv)\n",
    "display(dbutils.fs.ls(\"abfss://demo@formula1dl.dfs.core.windows.net\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93f80400-d8e7-4284-b084-e661af26407b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read data from csv file. Notice reading from csv by spark is a little different with reading by pandas\n",
    "# # in pandas we use read_csv but spark.read.csv is used based on spark library  \n",
    "spark.rea.csv(\"abfss://demo@fomula1dl.dfs.code.windows.net/circuets.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Access Azure dataset by SAS key",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
